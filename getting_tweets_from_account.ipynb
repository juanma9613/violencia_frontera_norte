{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import datetime\n",
    "import tweepy\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "import csv\n",
    "\n",
    "with open('creds.json') as json_file:\n",
    "    creds = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DEFENSORIAEC'"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = \"@DEFENSORIAEC\"\n",
    "user = user.replace(\"@\",\"\")\n",
    "\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392 mentions collected\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "def get_tweets_mentions(user, petitions = 4, newest_id_possible_path = 'newest_id_mentions.json'):\n",
    "    \n",
    "    if os.path.exists(newest_id_possible_path):\n",
    "        with open(newest_id_possible_path) as json_file:\n",
    "            data = json.load(json_file)\n",
    "            if user in data:\n",
    "                _since_id = data[user]\n",
    "            else:\n",
    "                _since_id = None   \n",
    "    else:\n",
    "        _since_id = None\n",
    "    \n",
    "    _max_id = None    \n",
    "    n_queries = 0\n",
    "    n_queries_user = 0\n",
    "    max_queries = petitions   \n",
    "    \n",
    "    auth = tweepy.AppAuthHandler(creds[\"client_key\"], creds[\"client_secret\"])\n",
    "    api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True)\n",
    "\n",
    "    tweets = tweet_batch = api.search(q = f'to:{user} OR @{user}',\n",
    "                                      tweet_mode = \"extended\",\n",
    "                                      count = 100,\n",
    "                                      result_type = 'recent',\n",
    "                                      since_id = _since_id,\n",
    "                                      max_id = _max_id)\n",
    "\n",
    "    n_queries += 1        \n",
    "    most_recent_id = tweet_batch.since_id\n",
    "    num_none_rows = 0\n",
    "    tweet_max_id = None\n",
    "    \n",
    "    while (n_queries < max_queries):\n",
    "        if tweet_batch.max_id is not None:\n",
    "            tweet_max_id = tweet_batch.max_id\n",
    "\n",
    "        tweet_batch = api.search(q = f'to:{user} OR @{user}',\n",
    "                                 result_type = 'recent',\n",
    "                                 count = 100,\n",
    "                                 max_id = tweet_max_id, \n",
    "                                 tweet_mode = 'extended',\n",
    "                                 since_id = _since_id)\n",
    "        \n",
    "        n_queries += 1\n",
    "        tweets.extend(tweet_batch)\n",
    "        \n",
    "        if len(tweet_batch) == 0:\n",
    "            num_none_rows += 1\n",
    "        else:\n",
    "            num_none_rows = 0\n",
    "\n",
    "        # end while if max_id is lower than since_id \n",
    "        if (tweet_max_id is not None) and (_since_id is not None):\n",
    "            if tweet_max_id < _since_id:\n",
    "                print('exited because tweet_max_id < since_id')\n",
    "                break\n",
    "\n",
    "        if num_none_rows > 6: #if 6 searches in a row are none then stop searching for that user\n",
    "            print('exited because there were 6 consecutive calls giving none')\n",
    "            break\n",
    "    \n",
    "    tweets_mentions = []\n",
    "    retweets_mentions = []\n",
    "    newest_tweet_id_mentions = {}\n",
    "\n",
    "    for idx, tweet in enumerate(tweets):        \n",
    "        \n",
    "        access_time = datetime.now().strftime(\"%Y %b %d %H:%M:%S\")\n",
    "        date = datetime.strptime(tweet._json[\"created_at\"], '%a %b %d %H:%M:%S %z %Y')\n",
    "        date_5 = date - timedelta(hours = 5)            \n",
    "        date_format = date_5.strftime(\"%Y %b %d %H:%M:%S\")\n",
    "        \n",
    "        if (tweet._json[\"user\"][\"screen_name\"] == user) and (tweet._json[\"in_reply_to_screen_name\"] == user):\n",
    "            pass \n",
    "        else:\n",
    "            # getting tweets\n",
    "            if ('RT @' not in tweet._json[\"full_text\"]):\n",
    "                temp = [tweet._json[\"id\"], access_time, date_format, tweet._json[\"user\"][\"screen_name\"], \n",
    "                        None, False, None, tweet._json[\"full_text\"]]\n",
    "                tweets_mentions.append(temp)\n",
    "\n",
    "            # getting retweets\n",
    "            else:\n",
    "                temp = [tweet._json[\"id\"], access_time, date_format, \n",
    "                        tweet._json[\"user\"][\"screen_name\"], None, True,\n",
    "                        tweet._json[\"retweeted_status\"][\"user\"][\"screen_name\"], \n",
    "                        tweet._json[\"retweeted_status\"][\"full_text\"]]\n",
    "                retweets_mentions.append(temp)\n",
    "            \n",
    "    if (user not in newest_tweet_id_mentions) and (most_recent_id is not None):\n",
    "        newest_tweet_id_mentions[user] = most_recent_id\n",
    "    \n",
    "    if most_recent_id is not None:\n",
    "        with open(newest_id_possible_path, 'w') as outfile:\n",
    "            json.dump(newest_tweet_id_mentions, outfile)           \n",
    "    \n",
    "    return tweets_mentions, retweets_mentions\n",
    "\n",
    "tw_m, rtw_m = get_tweets_mentions(user)\n",
    "print((len(tw_m) + len(rtw_m)), \"mentions collected\")\n",
    "\n",
    "df_tw_m = pd.DataFrame(tw_m, columns = ['id', 'fecha_consulta', 'fecha_escritura',\n",
    "                                      'cuenta_origen', 'query_busqueda',\n",
    "                                      'retweet', 'retweeted_from', 'texto'])\n",
    "\n",
    "df_rtw_m = pd.DataFrame(rtw_m, columns = ['id', 'fecha_consulta', 'fecha_escritura',\n",
    "                                          'cuenta_origen', 'query_busqueda',\n",
    "                                          'retweet', 'retweeted_from', 'texto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "940 tweets and 60 retweets collected\n"
     ]
    }
   ],
   "source": [
    "def get_tweets_timeline(user, petitions = 10, newest_id_possible_path = 'newest_id_tweets.json'):\n",
    "    \n",
    "    if os.path.exists(newest_id_possible_path):\n",
    "        with open(newest_id_possible_path) as json_file:\n",
    "            data = json.load(json_file)\n",
    "            if user in data:\n",
    "                _since_id = data[user]\n",
    "            else:\n",
    "                _since_id = None   \n",
    "    else:\n",
    "        _since_id = None\n",
    "    \n",
    "    _max_id = None    \n",
    "    n_queries = 0\n",
    "    n_queries_user = 0\n",
    "    max_queries = petitions    \n",
    "    \n",
    "    auth = tweepy.AppAuthHandler(creds[\"client_key\"], creds[\"client_secret\"])\n",
    "    api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True)\n",
    "\n",
    "    tweets = tweet_batch = api.user_timeline(screen_name = user,\n",
    "                                             tweet_mode = \"extended\",\n",
    "                                             count = 100,\n",
    "                                             result_type = 'recent',\n",
    "                                             since_id = _since_id,\n",
    "                                             max_id = _max_id)\n",
    "\n",
    "    n_queries += 1        \n",
    "    most_recent_id = tweet_batch.since_id\n",
    "    num_none_rows = 0\n",
    "    tweet_max_id = None    \n",
    "    \n",
    "    while (n_queries < max_queries):\n",
    "        \n",
    "            if tweet_batch.max_id is not None:\n",
    "                tweet_max_id = tweet_batch.max_id\n",
    "            \n",
    "            tweet_batch = api.user_timeline(screen_name = user,\n",
    "                                    result_type = 'recent',\n",
    "                                    count = 100,\n",
    "                                    max_id = tweet_max_id, \n",
    "                                    tweet_mode = 'extended',\n",
    "                                    since_id = _since_id)\n",
    "            \n",
    "            n_queries += 1\n",
    "            tweets.extend(tweet_batch)\n",
    "            \n",
    "            if len(tweet_batch) == 0:\n",
    "                num_none_rows += 1\n",
    "            else:\n",
    "                num_none_rows = 0\n",
    "\n",
    "            # end while if max_id is lower than since_id \n",
    "            if (tweet_max_id is not None) and (_since_id is not None):\n",
    "                if tweet_max_id < _since_id:\n",
    "                    print('exited because tweet_max_id < since_id')\n",
    "                    break\n",
    "\n",
    "            if num_none_rows > 6: #if 6 searches in a row are none then stop searching for that user\n",
    "                print('exited because there were 6 consecutive calls giving none')\n",
    "                break\n",
    "    \n",
    "    tweets_lst = []\n",
    "    retweets_lst = []\n",
    "    newest_tweet_id = {}\n",
    "\n",
    "    for idx, tweet in enumerate(tweets):\n",
    "        \n",
    "        access_time = datetime.now().strftime(\"%Y %b %d %H:%M:%S\")\n",
    "        date = datetime.strptime(tweet._json[\"created_at\"], '%a %b %d %H:%M:%S %z %Y')\n",
    "        date_5 = date - timedelta(hours = 5)            \n",
    "        date_format = date_5.strftime(\"%Y %b %d %H:%M:%S\") \n",
    "\n",
    "        # getting tweets\n",
    "        if ('RT @' not in tweet._json[\"full_text\"]):\n",
    "            temp = [tweet._json[\"id\"], access_time, date_format, tweet._json[\"user\"][\"screen_name\"], \n",
    "                    None, False, None, tweet._json[\"full_text\"]]\n",
    "            tweets_lst.append(temp)\n",
    "\n",
    "        # getting retweets\n",
    "        else:\n",
    "            temp = [tweet._json[\"id\"], access_time, date_format, \n",
    "                    tweet._json[\"user\"][\"screen_name\"], None, True,\n",
    "                    tweet._json[\"retweeted_status\"][\"user\"][\"screen_name\"], \n",
    "                    tweet._json[\"retweeted_status\"][\"full_text\"]]\n",
    "            retweets_lst.append(temp)\n",
    "            \n",
    "    if (user not in newest_tweet_id):\n",
    "        newest_tweet_id[user] = most_recent_id\n",
    "    \n",
    "    if most_recent_id is not None:\n",
    "        with open(newest_id_possible_path, 'w') as outfile:\n",
    "            json.dump(newest_tweet_id, outfile)\n",
    "        \n",
    "           \n",
    "    \n",
    "    return tweets_lst, retweets_lst\n",
    "\n",
    "tw, rtw = get_tweets_timeline(user)\n",
    "\n",
    "print(len(tw), \"tweets\", \"and\", len(rtw), \"retweets collected\")\n",
    "df_tw = pd.DataFrame(tw, columns=['id', 'fecha_consulta', 'fecha_escritura',\n",
    "                                  'cuenta_origen', 'query_busqueda',\n",
    "                                  'retweet', 'retweeted_from', 'texto'])\n",
    "\n",
    "\n",
    "\n",
    "df_rtw = pd.DataFrame(rtw, columns=['id', 'fecha_consulta', 'fecha_escritura',\n",
    "                                    'cuenta_origen', 'query_busqueda',\n",
    "                                    'retweet', 'retweeted_from', 'texto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dfs = [df_tw, df_rtw, df_tw_m, df_rtw_m]\n",
    "all_dfs = pd.concat(dfs, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_time = datetime.now().strftime(\"%Y_%b_%d_%H:%M:%S\")\n",
    "out = access_time + \"_cuentas.csv\"\n",
    "\n",
    "all_dfs.to_csv(out, sep = '\\t', index = False, header = True, quoting = csv.QUOTE_ALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
