{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from twarc import Twarc\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "with open('creds.json') as json_file:\n",
    "    creds = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##¬†Example tweets and retweets according to https://developer.twitter.com/en/docs/twitter-api/v1/tweets/timelines/api-reference/get-statuses-user_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "twarc_object = Twarc(creds[\"client_key\"], \n",
    "                     creds[\"client_secret\"], \n",
    "                     creds[\"access_token\"], \n",
    "                     creds[\"access_token_secret\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DEFENSORIAEC'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = \"@DEFENSORIAEC\"\n",
    "user = user.replace(\"@\",\"\")\n",
    "user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweets and retweets collected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def get_tweets(user, path_last_id='newest_id.json'):\n",
    "    try:\n",
    "        \n",
    "        with open(path_last_id) as json_file:\n",
    "            data = json.load(json_file)\n",
    "            if user in data:\n",
    "                _since_id = data[user]\n",
    "            else:\n",
    "                _since_id = None\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        _since_id = None\n",
    "        \n",
    "    \n",
    "    tweets = []\n",
    "    retweets = []\n",
    "    newest_tweet_id = {}\n",
    "\n",
    "    min_id = math.inf\n",
    "    max_id = - math.inf\n",
    "\n",
    "    for tweet in twarc_object.timeline(screen_name = user,\n",
    "                                       since_id = _since_id,\n",
    "                                       max_pages = 3):\n",
    "        access_time = datetime.now().strftime(\"%Y %b %d %H:%M:%S\")                                \n",
    "        date = datetime.strptime(tweet[\"created_at\"], '%a %b %d %H:%M:%S %z %Y')\n",
    "        date_5 = date - timedelta(hours = 5)            \n",
    "        date_format = date_5.strftime(\"%Y %b %d %H:%M:%S\")\n",
    "        \n",
    "        # date_tw_format = \"%a %b %d %H:%M:%S %Y\"\n",
    "        #print(access_time)\n",
    "        current_id = tweet[\"id\"]\n",
    "        if current_id > max_id:\n",
    "            max_id = current_id\n",
    "        if current_id < min_id:\n",
    "            min_id = current_id\n",
    "\n",
    "        # getting tweets\n",
    "        if ('RT @' not in tweet[\"full_text\"]):\n",
    "            \n",
    "            temp = [tweet[\"id\"], access_time, date_format, user, None, False, None, tweet[\"full_text\"]]\n",
    "            tweets.append(temp)\n",
    "\n",
    "        # getting retweets\n",
    "        else:\n",
    "           \n",
    "            temp = [tweet[\"id\"], access_time, date_format, user, None, True,\n",
    "                    tweet[\"retweeted_status\"][\"user\"][\"screen_name\"], tweet[\"retweeted_status\"][\"full_text\"]]\n",
    "            retweets.append(temp)\n",
    "    \n",
    "    print(\"Tweets and retweets collected\")\n",
    "            \n",
    "    if ((max_id != -math.inf) and (max_idx is not None)):\n",
    "        \n",
    "        newest_tweet_id[user] = max_id\n",
    "        \n",
    "        with open(path_last_id, 'w') as outfile:\n",
    "            json.dump(newest_tweet_id, outfile)\n",
    "            \n",
    "    return tweets, retweets\n",
    "    \n",
    "\n",
    "tw, rtw = get_tweets(user)\n",
    "len(tw), len(rtw)\n",
    "#print(tweets[1])\n",
    "     \n",
    "#tweets#[\"full_text\"]\n",
    "#retweets[0]#[\"retweeted_status\"][\"full_text\"]\n",
    "#min_id, max_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tw[0]\n",
    "\n",
    "#texts = []\n",
    "#for idx, tweet in enumerate(tweets):\n",
    "#    texts.append(tweet[\"full_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [id, fecha_consulta, fecha_escritura, cuenta_origen, query_busqueda, retweet, retweeted_from, texto]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#pd.DataFrame(texts)\n",
    "df_tw = pd.DataFrame(tw, columns=['id', 'fecha_consulta', 'fecha_escritura', 'cuenta_origen', 'query_busqueda',\n",
    "                                   'retweet', 'retweeted_from', 'texto'])\n",
    "\n",
    "\n",
    "df_rtw = pd.DataFrame(rtw, columns=['id', 'fecha_consulta', 'fecha_escritura', 'cuenta_origen', 'query_busqueda',\n",
    "                                   'retweet', 'retweeted_from', 'texto'])\n",
    "\n",
    "df_rtw.head()\n",
    "\n",
    "dfs = [df_tw, df_rtw]\n",
    "\n",
    "t_rt_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(t_rt_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(t_rt_df))\n",
    "t_rt_df.to_csv('tw_rtw.csv', sep = '\\t', index = True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example getting mentions according to https://developer.twitter.com/en/docs/twitter-api/v1/tweets/timelines/api-reference/get-statuses-mentions_timeline\n",
    "\n",
    "\n",
    "para este twarc no sirve, entonces mejor usar tweepy search usando los operadoers https://developer.twitter.com/en/docs/twitter-api/v1/rules-and-filtering/search-operators\n",
    "\n",
    "https://docs.tweepy.org/en/latest/api.html\n",
    "https://docs.tweepy.org/en/latest/api.html#search-methods\n",
    "\n",
    "\n",
    "toca verificar que esta opcion no est√© incluyendo los tweeets que "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'to:DEFENSORIAEC OR @DEFENSORIAEC'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f'to:{user} OR @{user}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets_batch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-78f02bdd2923>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0mtw_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrtw_m\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tweets_mentions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-78f02bdd2923>\u001b[0m in \u001b[0;36mget_tweets_mentions\u001b[0;34m(user, petitions)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mn_queries\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mmost_recent_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtweets_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msince_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mnum_none_rows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mtweet_max_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tweets_batch' is not defined"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "            \n",
    "def get_tweets_mentions(user, petitions = 50):\n",
    "    #add numbers petitions per api -50\n",
    "    \n",
    "    try:\n",
    "        \n",
    "        with open('newest_id_mentions.json') as json_file:\n",
    "            data = json.load(json_file)\n",
    "            if user in data:\n",
    "                _since_id = data[user]\n",
    "            else:\n",
    "                _since_id = None\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        _since_id = None\n",
    "    \n",
    "    _max_id = None\n",
    "    \n",
    "    \n",
    "    max_queries = 430\n",
    "    min_calls_per_user = petitions\n",
    "    max_queries_per_user = 120 \n",
    "    n_tweets_user = max_queries_per_user * 100\n",
    "    n_queries = 0\n",
    "    n_queries_user = 0\n",
    "    \n",
    "    \n",
    "    auth = tweepy.AppAuthHandler(creds[\"client_key\"], creds[\"client_secret\"])\n",
    "    api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True)\n",
    "\n",
    "    tweets = tweet_batch = api.search(q = f'to:{user} OR @{user}',  tweet_mode = \"extended\", count = n_tweets_user,\n",
    "                        result_type = 'recent', since_id = _since_id, max_id = _max_id)\n",
    "\n",
    "    #tweets #tweets arriba es una lista de statuses\n",
    "    #dir(tweets[0]) # cada status tiene los siguentes metodos y atributos, el mas importante es ._json que convierte el status en un dicconario.\n",
    "    n_queries_user +=1 \n",
    "    n_queries += 1\n",
    "        \n",
    "    most_recent_id = tweets_batch.since_id\n",
    "    num_none_rows = 0\n",
    "    tweet_max_id = None\n",
    "    \n",
    "    \n",
    "    while ((n_queries_user < max_queries_per_user) and (n_queries < max_queries)):\n",
    "            if tweet_batch.max_id is not None:\n",
    "                tweet_max_id = tweet_batch.max_id\n",
    "            \n",
    "            tweet_batch = api.search(q = f'to:{user} OR @{user}', lang = lang,\n",
    "                                    count = n_tweets_user,\n",
    "                                    max_id = tweet_max_id, \n",
    "                                    tweet_mode = 'extended',\n",
    "                                    since_id = _since_id)\n",
    "            n_queries_user += 1\n",
    "            n_queries += 1\n",
    "            tweets.extend(tweet_batch)\n",
    "            if len(tweet_batch) == 0:\n",
    "                num_none_rows += 1\n",
    "            else:\n",
    "                num_none_rows = 0\n",
    "\n",
    "            # end while if max_id is lower than since_id \n",
    "            if (tweet_max_id is not None) and (_since_id is not None):\n",
    "                if tweet_max_id < _since_id:\n",
    "                    print('exited because tweet_max_id < since_id')\n",
    "                    break\n",
    "\n",
    "            if num_none_rows > 6: #if 6 searches in a row are none then stop searching for that user\n",
    "                print('exited because there were 6 consecutive calls giving none')\n",
    "                break\n",
    "    \n",
    "    tweets_mentions = []\n",
    "    retweets_mentions = []\n",
    "    newest_tweet_id_mentions = {}\n",
    "\n",
    "    for idx, tweet in enumerate(tweets):\n",
    "        \n",
    "        access_time = datetime.now().strftime(\"%Y %b %d %H:%M:%S\")\n",
    "        date = datetime.strptime(tweet._json[\"created_at\"], '%a %b %d %H:%M:%S %z %Y')\n",
    "        date_5 = date - timedelta(hours = 5)            \n",
    "        date_format = date_5.strftime(\"%Y %b %d %H:%M:%S\") \n",
    "\n",
    "        # getting tweets\n",
    "        if ('RT @' not in tweet._json[\"full_text\"]):\n",
    "            \n",
    "            temp = [tweet._json[\"id\"], access_time, date_format, tweet._json[\"user\"][\"screen_name\"], \n",
    "                    None, False, None, tweet._json[\"full_text\"]]\n",
    "            tweets_mentions.append(temp)\n",
    "\n",
    "        # getting retweets\n",
    "        else:\n",
    "\n",
    "            temp = [tweet._json[\"id\"], access_time, date_format, \n",
    "                    tweet._json[\"user\"][\"screen_name\"], None, True,\n",
    "                    tweet._json[\"retweeted_status\"][\"user\"][\"screen_name\"], \n",
    "                    tweet._json[\"retweeted_status\"][\"full_text\"]]\n",
    "            #print(temp)\n",
    "            #break\n",
    "            retweets_mentions.append(temp)\n",
    "            \n",
    "    if user not in newest_tweet_id_mentions:\n",
    "        newest_tweet_id_mentions[user] = most_recent_id\n",
    "        \n",
    "    with open('newest_id_mentions.json', 'w') as outfile:\n",
    "        json.dump(newest_tweet_id_mentions, outfile)\n",
    "        \n",
    "           \n",
    "    print(\"Mentions Tweets and retweets collected\")\n",
    "    return tweets_mentions, retweets_mentions\n",
    "    \n",
    "\n",
    "tw_m, rtw_m = get_tweets_mentions(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     id        fecha_consulta       fecha_escritura  \\\n",
      "0   1357862360875204608  2021 Feb 05 20:34:04  2021 Feb 06 01:23:09   \n",
      "1   1357859450837753860  2021 Feb 05 20:34:04  2021 Feb 06 01:11:35   \n",
      "2   1357857969505984515  2021 Feb 05 20:34:04  2021 Feb 06 01:05:42   \n",
      "3   1357857455930290177  2021 Feb 05 20:34:04  2021 Feb 06 01:03:39   \n",
      "4   1357856815132905472  2021 Feb 05 20:34:04  2021 Feb 06 01:01:07   \n",
      "5   1357853147486695425  2021 Feb 05 20:34:04  2021 Feb 06 00:46:32   \n",
      "6   1357853132580155396  2021 Feb 05 20:34:04  2021 Feb 06 00:46:29   \n",
      "7   1357852447092465664  2021 Feb 05 20:34:04  2021 Feb 06 00:43:45   \n",
      "8   1357852083148500993  2021 Feb 05 20:34:04  2021 Feb 06 00:42:18   \n",
      "9   1357851883940040705  2021 Feb 05 20:34:04  2021 Feb 06 00:41:31   \n",
      "10  1357849948822380547  2021 Feb 05 20:34:04  2021 Feb 06 00:33:50   \n",
      "11  1357849601882148865  2021 Feb 05 20:34:04  2021 Feb 06 00:32:27   \n",
      "12  1357849049811083265  2021 Feb 05 20:34:04  2021 Feb 06 00:30:15   \n",
      "13  1357848536738594818  2021 Feb 05 20:34:04  2021 Feb 06 00:28:13   \n",
      "14  1357847898252333056  2021 Feb 05 20:34:04  2021 Feb 06 00:25:41   \n",
      "15  1357847701333962752  2021 Feb 05 20:34:04  2021 Feb 06 00:24:54   \n",
      "16  1357847167281598465  2021 Feb 05 20:34:04  2021 Feb 06 00:22:46   \n",
      "17  1357847166010748928  2021 Feb 05 20:34:04  2021 Feb 06 00:22:46   \n",
      "18  1357846276776333312  2021 Feb 05 20:34:04  2021 Feb 06 00:19:14   \n",
      "19  1357845017319112707  2021 Feb 05 20:34:04  2021 Feb 06 00:14:14   \n",
      "\n",
      "      cuenta_origen query_busqueda  retweet in_replay_to  \\\n",
      "0     vicenteconcha           None    False         None   \n",
      "1       Seguiencasa           None    False         None   \n",
      "2    vickyvalverdeg           None    False         None   \n",
      "3   CRiveraC_France           None    False         None   \n",
      "4        wendyta_87           None    False         None   \n",
      "5    NelaMaldonado3           None    False         None   \n",
      "6          Helen90R           None    False         None   \n",
      "7        resteban89           None    False         None   \n",
      "8    PesantesMikael           None    False         None   \n",
      "9        james_quim           None    False         None   \n",
      "10        JLeoMoran           None    False         None   \n",
      "11   PesantesMikael           None    False         None   \n",
      "12        JLeoMoran           None    False         None   \n",
      "13         jorsalmo           None    False         None   \n",
      "14     HijadelSol17           None    False         None   \n",
      "15           mvaca1           None    False         None   \n",
      "16       elgabomora           None    False         None   \n",
      "17           mvaca1           None    False         None   \n",
      "18           mvaca1           None    False         None   \n",
      "19         Nancy23a           None    False         None   \n",
      "\n",
      "                                                texto  \n",
      "0   Y pensar que van 240 min, y sigo esperando @Cl...  \n",
      "1   Quien va a tomar cuentas con esta seudo emplea...  \n",
      "2   @ClaroEcua por qu√© tengo que agendar cita e ir...  \n",
      "3   üî¥ REDH, Ecuador: En defensa de la democracia, ...  \n",
      "4   En su calidad de m√°xima autoridad de la @DEFEN...  \n",
      "5   @MeraZambrano_ @LoloMino @DEFENSORIAEC Migraci...  \n",
      "6   @GuayasCna @Salud_Ec @Lenin @DerechoSaludAN La...  \n",
      "7   Vale la pena recalcar que, a pretexto de la pa...  \n",
      "8   @revistavistazo JAJAJAJAJA SOLO USTEDES, EST√öP...  \n",
      "9   @CNEL_EP Otra semana y no arreglan las luminar...  \n",
      "10  @EmilioLitardo @JorgeWated Acudamos a la @DEFE...  \n",
      "11  @Expresoec AQU√ç ES MEJOR, LOS POL√çTICOS ECUATO...  \n",
      "12  @EmilioLitardo @JorgeWated Me indicaron ahi mi...  \n",
      "13  @DEFENSORIAEC @AnahiDurandG @lahoraecuador @el...  \n",
      "14  @wambraEc @marvinblack011 @freddcarrion @Salud...  \n",
      "15  @CarlosVerareal @Lenin @LassoGuillermo @FEGASG...  \n",
      "16  @DEFENSORIAEC el servicio es una porqueria, ni...  \n",
      "17  @CarlosVerareal @Lenin @LassoGuillermo @FEGASG...  \n",
      "18  @CarlosVerareal @Lenin @LassoGuillermo @FEGASG...  \n",
      "19  @Lenin No se ha cumplido la ley humanitaria! A...  \n"
     ]
    }
   ],
   "source": [
    "df_tw_m = pd.DataFrame(tw_m, columns=['id', 'fecha_consulta', 'fecha_escritura', 'cuenta_origen', 'query_busqueda',\n",
    "                                   'retweet', 'in_replay_to', 'texto'])\n",
    "\n",
    "df_rtw_m = pd.DataFrame(rtw_m, columns=['id', 'fecha_consulta', 'fecha_escritura', 'cuenta_origen', 'query_busqueda',\n",
    "                                   'retweet', 'in_replay_to', 'texto'])\n",
    "\n",
    "\n",
    "dfs2 = [df_tw_m, df_rtw_m]\n",
    "\n",
    "t_rt_df_m = pd.concat(dfs2, ignore_index=True)\n",
    "\n",
    "print(t_rt_df_m.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_rt_df_m.to_csv('/home/noone/Desktop/vfn/violencia_frontera_norte/tw_rtw_m.csv', sep = '\\t', index = True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mentions Tweets and retweets collected\n",
      "                     id        fecha_consulta       fecha_escritura  \\\n",
      "0   1357840496522051587  2021 Feb 05 20:42:49  2021 Feb 05 23:56:16   \n",
      "1   1357840003955580929  2021 Feb 05 20:42:49  2021 Feb 05 23:54:19   \n",
      "2   1357838902397140993  2021 Feb 05 20:42:49  2021 Feb 05 23:49:56   \n",
      "3   1357838097132716034  2021 Feb 05 20:42:49  2021 Feb 05 23:46:44   \n",
      "4   1357836585262325764  2021 Feb 05 20:42:49  2021 Feb 05 23:40:43   \n",
      "5   1357833777515528198  2021 Feb 05 20:42:49  2021 Feb 05 23:29:34   \n",
      "6   1357831743055794178  2021 Feb 05 20:42:49  2021 Feb 05 23:21:29   \n",
      "7   1357827704368857088  2021 Feb 05 20:42:49  2021 Feb 05 23:05:26   \n",
      "8   1357825034040061957  2021 Feb 05 20:42:49  2021 Feb 05 22:54:49   \n",
      "9   1357824854179909632  2021 Feb 05 20:42:49  2021 Feb 05 22:54:07   \n",
      "10  1357824228498808832  2021 Feb 05 20:42:49  2021 Feb 05 22:51:37   \n",
      "11  1357824150434426881  2021 Feb 05 20:42:49  2021 Feb 05 22:51:19   \n",
      "12  1357824061649338371  2021 Feb 05 20:42:49  2021 Feb 05 22:50:58   \n",
      "13  1357823987502505986  2021 Feb 05 20:42:49  2021 Feb 05 22:50:40   \n",
      "14  1357823924550123520  2021 Feb 05 20:42:49  2021 Feb 05 22:50:25   \n",
      "15  1357823877108428802  2021 Feb 05 20:42:49  2021 Feb 05 22:50:14   \n",
      "16  1357823756199227397  2021 Feb 05 20:42:49  2021 Feb 05 22:49:45   \n",
      "17  1357823505132384256  2021 Feb 05 20:42:49  2021 Feb 05 22:48:45   \n",
      "18  1357840335615889409  2021 Feb 05 20:42:49  2021 Feb 05 23:55:38   \n",
      "19  1357840142321545219  2021 Feb 05 20:42:49  2021 Feb 05 23:54:52   \n",
      "\n",
      "      cuenta_origen query_busqueda  retweet  in_replay_to  \\\n",
      "0   rocioguevara123           None    False          None   \n",
      "1      martharizzog           None    False          None   \n",
      "2        lucciola54           None    False          None   \n",
      "3         jlfalquez           None    False          None   \n",
      "4      Elian_Musica           None    False          None   \n",
      "5      Leon84Victor           None    False          None   \n",
      "6         Diego0665           None    False          None   \n",
      "7            CNT_EC           None    False          None   \n",
      "8         ClaroEcua           None    False          None   \n",
      "9        wendyta_87           None    False          None   \n",
      "10  PatyGon96493246           None    False          None   \n",
      "11  PatyGon96493246           None    False          None   \n",
      "12  PatyGon96493246           None    False          None   \n",
      "13  PatyGon96493246           None    False          None   \n",
      "14  Wonder_women84_           None    False          None   \n",
      "15  PatyGon96493246           None    False          None   \n",
      "16  PatyGon96493246           None    False          None   \n",
      "17        interagua           None    False          None   \n",
      "18       sisa_killa           None     True  edicionmedEC   \n",
      "19  CarlosNeiraFlor           None     True  edicionmedEC   \n",
      "\n",
      "                                                texto  \n",
      "0   @EfrenIcaza @FiscaliaEcuador @cnegobec @DianaA...  \n",
      "1   @Elian_Musica @CasadelaCultura @cpccs @DEFENSO...  \n",
      "2   @Jolsam @FUNDHEC @DrJuanCZevallos @JorgeWated ...  \n",
      "3   @wambraEc @BadLlamaEc @freddcarrion @Salud_Ec ...  \n",
      "4   üî¥URGENTEüî¥\\nEn sesi√≥n plenaria la @CasadelaCult...  \n",
      "5   @DEFENSORIAEC EXCELENTE LO QUE SE NECESITA EN ...  \n",
      "6   @edicionmedEC @forosaludec @freddcarrion @DEFE...  \n",
      "7   @enriquez_homero @Arcotel_ec @DEFENSORIAEC @en...  \n",
      "8   @Wonder_women84_ @NetlifeEcuador @DEFENSORIAEC...  \n",
      "9   @JorgeWated hasta el presente momento jam√°s me...  \n",
      "10  #JusticiaMSP Sres. jueces constitucionales sol...  \n",
      "11  #JusticiaMSP Sres. jueces constitucionales sol...  \n",
      "12  #JusticiaMSP Sres. jueces constitucionales sol...  \n",
      "13  #JusticiaMSP Sres. jueces constitucionales sol...  \n",
      "14  Srs. de @NetlifeEcuador me indican que se han ...  \n",
      "15  #JusticiaMSP Sres. jueces constitucionales sol...  \n",
      "16  #JusticiaMSP Sres. jueces constitucionales sol...  \n",
      "17  @fatty1017ec @DEFENSORIAEC Estimada @fatty1017...  \n",
      "18  #ATENCI√ìN Ministerio de Salud se niega a entre...  \n",
      "19  #ATENCI√ìN Ministerio de Salud se niega a entre...  \n"
     ]
    }
   ],
   "source": [
    "var = 1357840643586940000\n",
    "\n",
    "tweets = api.search(q = f'to:{user} OR @{user}',  tweet_mode = \"extended\", count = 100, result_type = 'recent', max_id = var)\n",
    "\n",
    "\n",
    "tw_m, rtw_m = get_tweets_mentions(user)\n",
    "\n",
    "\n",
    "df_tw_m = pd.DataFrame(tw_m, columns=['id', 'fecha_consulta', 'fecha_escritura', 'cuenta_origen', 'query_busqueda',\n",
    "                                   'retweet', 'in_replay_to', 'texto'])\n",
    "\n",
    "df_rtw_m = pd.DataFrame(rtw_m, columns=['id', 'fecha_consulta', 'fecha_escritura', 'cuenta_origen', 'query_busqueda',\n",
    "                                   'retweet', 'in_replay_to', 'texto'])\n",
    "\n",
    "\n",
    "dfs2 = [df_tw_m, df_rtw_m]\n",
    "\n",
    "t_rt_df_m = pd.concat(dfs2, ignore_index=True)\n",
    "\n",
    "print(t_rt_df_m.head(20))\n",
    "\n",
    "t_rt_df_m.to_csv('/home/noone/Desktop/vfn/violencia_frontera_norte/tw_rtw_m2.csv', sep = '\\t', index = True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##¬†Get user timeline tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from twarc import Twarc\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import datetime\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "\n",
    "with open('creds.json') as json_file:\n",
    "    creds = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "def get_tweets_mentions3(user, petitions = 4, newest_id_possible_path='newest_id_mentions.json'):\n",
    "    \n",
    "    if os.path.exists(newest_id_possible_path):\n",
    "        with open(newest_id_possible_path) as json_file:\n",
    "            data = json.load(json_file)\n",
    "            if user in data:\n",
    "                _since_id = data[user]\n",
    "            else:\n",
    "                _since_id = None   \n",
    "    else:\n",
    "        _since_id = None\n",
    "    \n",
    "    _max_id = None\n",
    "    \n",
    "    \n",
    "    print('_since_id', _since_id)\n",
    "    print('_max_id', _max_id)\n",
    "\n",
    "\n",
    "    n_queries = 0\n",
    "    n_queries_user = 0\n",
    "    max_queries = petitions\n",
    "    \n",
    "    \n",
    "    auth = tweepy.AppAuthHandler(creds[\"client_key\"], creds[\"client_secret\"])\n",
    "    api = tweepy.API(auth, wait_on_rate_limit = True, wait_on_rate_limit_notify = True)\n",
    "\n",
    "    tweets = tweet_batch = api.search(q = f'to:{user} OR @{user}',  tweet_mode = \"extended\", count = 100,\n",
    "                        result_type = 'recent', since_id = _since_id, max_id = _max_id)\n",
    "\n",
    "    #tweets #tweets arriba es una lista de statuses\n",
    "    #dir(tweets[0]) # cada status tiene los siguentes metodos y atributos, el mas importante es ._json que convierte el status en un dicconario.\n",
    "    n_queries += 1\n",
    "        \n",
    "    most_recent_id = tweet_batch.since_id\n",
    "    num_none_rows = 0\n",
    "    tweet_max_id = None\n",
    "    \n",
    "    \n",
    "    while (n_queries < max_queries):\n",
    "            if tweet_batch.max_id is not None:\n",
    "                tweet_max_id = tweet_batch.max_id\n",
    "            \n",
    "            tweet_batch = api.search(q = f'to:{user} OR @{user}',\n",
    "                                     result_type = 'recent',\n",
    "                                    count = 100,\n",
    "                                    max_id = tweet_max_id, \n",
    "                                    tweet_mode = 'extended',\n",
    "                                    since_id = _since_id)\n",
    "            n_queries += 1\n",
    "            tweets.extend(tweet_batch)\n",
    "            if len(tweet_batch) == 0:\n",
    "                num_none_rows += 1\n",
    "            else:\n",
    "                num_none_rows = 0\n",
    "\n",
    "            # end while if max_id is lower than since_id \n",
    "            if (tweet_max_id is not None) and (_since_id is not None):\n",
    "                if tweet_max_id < _since_id:\n",
    "                    print('exited because tweet_max_id < since_id')\n",
    "                    break\n",
    "\n",
    "            if num_none_rows > 6: #if 6 searches in a row are none then stop searching for that user\n",
    "                print('exited because there were 6 consecutive calls giving none')\n",
    "                break\n",
    "    \n",
    "    tweets_mentions = []\n",
    "    retweets_mentions = []\n",
    "    newest_tweet_id_mentions = {}\n",
    "\n",
    "    for idx, tweet in enumerate(tweets):\n",
    "        \n",
    "        access_time = datetime.now().strftime(\"%Y %b %d %H:%M:%S\")\n",
    "        date = datetime.strptime(tweet._json[\"created_at\"], '%a %b %d %H:%M:%S %z %Y')\n",
    "        date_5 = date - timedelta(hours = 5)            \n",
    "        date_format = date_5.strftime(\"%Y %b %d %H:%M:%S\") \n",
    "\n",
    "        # getting tweets\n",
    "        if ('RT @' not in tweet._json[\"full_text\"]):\n",
    "            \n",
    "            temp = [tweet._json[\"id\"], access_time, date_format, tweet._json[\"user\"][\"screen_name\"], \n",
    "                    None, False, None, tweet._json[\"full_text\"]]\n",
    "            tweets_mentions.append(temp)\n",
    "\n",
    "        # getting retweets\n",
    "        else:\n",
    "\n",
    "            temp = [tweet._json[\"id\"], access_time, date_format, \n",
    "                    tweet._json[\"user\"][\"screen_name\"], None, True,\n",
    "                    tweet._json[\"retweeted_status\"][\"user\"][\"screen_name\"], \n",
    "                    tweet._json[\"retweeted_status\"][\"full_text\"]]\n",
    "            #print(temp)\n",
    "            #break\n",
    "            retweets_mentions.append(temp)\n",
    "            \n",
    "    if user not in newest_tweet_id_mentions:\n",
    "        newest_tweet_id_mentions[user] = most_recent_id\n",
    "    \n",
    "    if most_recent_id is not None:\n",
    "        with open(newest_id_possible_path, 'w') as outfile:\n",
    "            json.dump(newest_tweet_id_mentions, outfile)\n",
    "        \n",
    "           \n",
    "    print(\"Mentions Tweets and retweets collected\")\n",
    "    return tweets_mentions, retweets_mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_since_id 1358102498096140288\n",
      "_max_id None\n",
      "Mentions Tweets and retweets collected\n"
     ]
    }
   ],
   "source": [
    "tw, rtw = get_tweets_mentions3(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rtw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
